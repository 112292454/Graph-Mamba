"""å…¨é¢ä¸¥æ ¼éªŒè¯å¯¼å‡ºç³»ç»Ÿ - éªŒè¯æ‰€æœ‰å›¾ï¼Œæ‰€æœ‰æ•°æ®é›†"""

import sys
import numpy as np
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from config import ProjectConfig
from src.data.unified_data_interface import UnifiedDataInterface
from export_system import create_true_exporter, load_data


def comprehensive_validate_dataset(dataset_name: str, config: ProjectConfig) -> bool:
    """å…¨é¢éªŒè¯å•ä¸ªæ•°æ®é›†çš„æ‰€æœ‰å›¾"""
    print(f"\nğŸ” å…¨é¢éªŒè¯ {dataset_name} æ•°æ®é›†")
    print("=" * 70)
    
    try:
        # 1. é‡æ–°å¯¼å‡ºæ•°æ®é›†
        print("ğŸ“‚ æ­¥éª¤1: é‡æ–°å¯¼å‡ºæ•°æ®é›†...")
        exporter = create_true_exporter(dataset_name, config)
        exporter.export()
        
        # 2. åŠ è½½åŸå§‹æ•°æ®å’Œå¯¼å‡ºæ•°æ®
        print("ğŸ“Š æ­¥éª¤2: åŠ è½½åŸå§‹æ•°æ®å’Œå¯¼å‡ºæ•°æ®...")
        
        # åŠ è½½åŸå§‹æ•°æ®
        udi = UnifiedDataInterface(config=config, dataset=dataset_name)
        udi.preload_graphs()
        loader = udi.get_dataset_loader()
        train_data, val_data, test_data, train_labels, val_labels, test_labels = loader.load_data()
        
        # è·å–åŸå§‹åˆ’åˆ†
        original_splits = udi.get_split_indices()
        
        # åˆå¹¶åŸå§‹æ•°æ®
        all_data = train_data + val_data + test_data
        all_labels = train_labels + val_labels + test_labels
        original_graphs = [sample['dgl_graph'] for sample in all_data]
        
        # åŠ è½½å¯¼å‡ºæ•°æ®
        output_file = Path("data/exported") / f"{dataset_name}_export.pkl"
        exported_data = load_data(output_file)
        
        total_graphs = len(original_graphs)
        print(f"  - æ•°æ®é›†è§„æ¨¡: {total_graphs} ä¸ªå›¾")
        print(f"  - åˆ’åˆ†: è®­ç»ƒ{len(original_splits['train'])}, éªŒè¯{len(original_splits['val'])}, æµ‹è¯•{len(original_splits['test'])}")
        
        # 3. ä¸¥æ ¼éªŒè¯åˆ’åˆ†ç´¢å¼•
        print("ğŸ” æ­¥éª¤3: ä¸¥æ ¼éªŒè¯åˆ’åˆ†ç´¢å¼•...")
        exported_splits = exported_data['splits']
        
        for split_name in ['train', 'val', 'test']:
            original_idx = np.array(original_splits[split_name], dtype=np.int64)
            exported_idx = exported_splits[split_name]
            
            if not np.array_equal(original_idx, exported_idx):
                print(f"âŒ {split_name}åˆ’åˆ†ç´¢å¼•ä¸ä¸€è‡´!")
                return False
            
            print(f"  âœ… {split_name}åˆ’åˆ†ç´¢å¼•å®Œå…¨ä¸€è‡´ (é•¿åº¦: {len(original_idx)})")
        
        # 4. å…¨é¢éªŒè¯æ‰€æœ‰å›¾çš„ç»“æ„å’Œç‰¹å¾
        print(f"ğŸ” æ­¥éª¤4: å…¨é¢éªŒè¯æ‰€æœ‰ {total_graphs} ä¸ªå›¾çš„ç»“æ„å’Œç‰¹å¾...")
        
        # æ˜¾ç¤ºè¿›åº¦çš„é—´éš”
        progress_interval = max(1, total_graphs // 20)  # æ¯5%æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
        
        for graph_idx in range(total_graphs):
            if graph_idx % progress_interval == 0:
                progress = (graph_idx / total_graphs) * 100
                print(f"    è¿›åº¦: {graph_idx}/{total_graphs} ({progress:.1f}%)")
            
            original_graph = original_graphs[graph_idx]
            exported_graph = exported_data['graphs'][graph_idx]
            
            # 4.1 åŸºæœ¬ç»“æ„éªŒè¯
            if original_graph.num_nodes() != exported_graph['num_nodes']:
                print(f"âŒ å›¾{graph_idx}: èŠ‚ç‚¹æ•°ä¸åŒ¹é… {original_graph.num_nodes()} vs {exported_graph['num_nodes']}")
                return False
                
            if original_graph.num_edges() != len(exported_graph['src']):
                print(f"âŒ å›¾{graph_idx}: è¾¹æ•°ä¸åŒ¹é… {original_graph.num_edges()} vs {len(exported_graph['src'])}")
                return False
            
            # 4.2 è¾¹è¿æ¥å…³ç³»éªŒè¯
            orig_src, orig_dst = original_graph.edges()
            orig_src_np = orig_src.numpy()
            orig_dst_np = orig_dst.numpy()
            exp_src = exported_graph['src']
            exp_dst = exported_graph['dst']
            
            if not np.array_equal(orig_src_np, exp_src):
                print(f"âŒ å›¾{graph_idx}: æºèŠ‚ç‚¹è¿æ¥ä¸åŒ¹é…")
                return False
                
            if not np.array_equal(orig_dst_np, exp_dst):
                print(f"âŒ å›¾{graph_idx}: ç›®æ ‡èŠ‚ç‚¹è¿æ¥ä¸åŒ¹é…")
                return False
            
            # 4.3 èŠ‚ç‚¹ç‰¹å¾å®Œå…¨éªŒè¯
            orig_num_nodes = original_graph.num_nodes()
            expected_node_tokens = loader.get_node_tokens_bulk(original_graph, list(range(orig_num_nodes)))
            expected_node_array = np.array(expected_node_tokens, dtype=np.int64)
            exported_node_feat = exported_graph['node_feat']
            
            if not np.array_equal(expected_node_array, exported_node_feat):
                print(f"âŒ å›¾{graph_idx}: èŠ‚ç‚¹ç‰¹å¾ä¸åŒ¹é…")
                print(f"    æœŸæœ›å½¢çŠ¶: {expected_node_array.shape}, å¯¼å‡ºå½¢çŠ¶: {exported_node_feat.shape}")
                return False
            
            # 4.4 è¾¹ç‰¹å¾å®Œå…¨éªŒè¯
            orig_num_edges = original_graph.num_edges()
            if orig_num_edges > 0:
                expected_edge_tokens = loader.get_edge_tokens_bulk(original_graph, list(range(orig_num_edges)))
                expected_edge_array = np.array(expected_edge_tokens, dtype=np.int64)
                exported_edge_feat = exported_graph['edge_feat']
                
                if not np.array_equal(expected_edge_array, exported_edge_feat):
                    print(f"âŒ å›¾{graph_idx}: è¾¹ç‰¹å¾ä¸åŒ¹é…")
                    print(f"    æœŸæœ›å½¢çŠ¶: {expected_edge_array.shape}, å¯¼å‡ºå½¢çŠ¶: {exported_edge_feat.shape}")
                    return False
        
        print(f"  âœ… æ‰€æœ‰ {total_graphs} ä¸ªå›¾çš„ç»“æ„å’Œç‰¹å¾éªŒè¯é€šè¿‡")
        
        # 5. éªŒè¯æ‰€æœ‰æ ‡ç­¾ä¸€è‡´æ€§
        print("ğŸ” æ­¥éª¤5: éªŒè¯æ‰€æœ‰æ ‡ç­¾ä¸€è‡´æ€§...")
        exported_labels = exported_data['labels']
        
        if len(all_labels) != len(exported_labels):
            print(f"âŒ æ ‡ç­¾æ•°é‡ä¸åŒ¹é…: {len(all_labels)} vs {len(exported_labels)}")
            return False
        
        label_mismatch_count = 0
        for graph_idx in range(len(all_labels)):
            original_label = all_labels[graph_idx]
            exported_label = exported_labels[graph_idx]
            
            if not _labels_equal(original_label, exported_label):
                label_mismatch_count += 1
                if label_mismatch_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªä¸åŒ¹é…çš„æ ‡ç­¾
                    print(f"âŒ å›¾ {graph_idx} æ ‡ç­¾ä¸åŒ¹é…: {original_label} vs {exported_label}")
                
        if label_mismatch_count > 0:
            print(f"âŒ æ€»è®¡ {label_mismatch_count} ä¸ªæ ‡ç­¾ä¸åŒ¹é…")
            return False
        
        print(f"  âœ… æ‰€æœ‰ {len(all_labels)} ä¸ªæ ‡ç­¾éªŒè¯é€šè¿‡")
        
        # 6. éªŒè¯å›¾çš„è¾¹å­˜å‚¨æ–¹å¼
        print("ğŸ” æ­¥éª¤6: éªŒè¯å›¾çš„è¾¹å­˜å‚¨æ–¹å¼...")
        sample_graph = original_graphs[0]
        sample_exported = exported_data['graphs'][0]
        
        orig_src, orig_dst = sample_graph.edges()
        edge_set = set(zip(orig_src.tolist(), orig_dst.tolist()))
        reverse_edge_set = set(zip(orig_dst.tolist(), orig_src.tolist()))
        is_undirected = len(edge_set & reverse_edge_set) > 0
        
        print(f"    - å›¾ç±»å‹: {'æ— å‘å›¾(åŒå‘è¾¹)' if is_undirected else 'æœ‰å‘å›¾'}")
        print(f"    - DGLè¾¹æ•°: {len(orig_src)}")
        print(f"    - å¯¼å‡ºè¾¹æ•°: {len(sample_exported['src'])}")
        print("    âœ… è¾¹å­˜å‚¨æ–¹å¼éªŒè¯é€šè¿‡")
        
        print(f"\nğŸ‰ {dataset_name} å…¨é¢éªŒè¯å®Œå…¨é€šè¿‡!")
        print(f"    éªŒè¯äº† {total_graphs} ä¸ªå›¾çš„å®Œæ•´ç»“æ„å’Œç‰¹å¾")
        return True
        
    except Exception as e:
        print(f"âŒ {dataset_name} å…¨é¢éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def _labels_equal(label1, label2) -> bool:
    """æ¯”è¾ƒä¸¤ä¸ªæ ‡ç­¾æ˜¯å¦ç›¸ç­‰"""
    try:
        if isinstance(label1, dict) and isinstance(label2, dict):
            if set(label1.keys()) != set(label2.keys()):
                return False
            for key in label1.keys():
                if abs(float(label1[key]) - float(label2[key])) > 1e-6:
                    return False
            return True
        elif isinstance(label1, (list, np.ndarray)) and isinstance(label2, (list, np.ndarray)):
            return np.allclose(np.array(label1), np.array(label2), atol=1e-6)
        else:
            return abs(float(label1) - float(label2)) < 1e-6
    except:
        return label1 == label2


def main():
    """å…¨é¢éªŒè¯ä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹å…¨é¢éªŒè¯å¯¼å‡ºç³»ç»Ÿ...")
    
    config = ProjectConfig()
    
    # æˆåŠŸå¯¼å‡ºçš„æ‰€æœ‰æ•°æ®é›†
    all_datasets = [
        "qm9", "zinc", "molhiv", "aqsol", "colors3", "proteins", 
        "dd", "mutagenicity", "coildel", "dblp", "twitter", 
        "synthetic", "peptides_func", "peptides_struct"
    ]
    
    success_count = 0
    total_graphs_validated = 0
    
    for dataset in all_datasets:
        if comprehensive_validate_dataset(dataset, config):
            success_count += 1
            
            # ç»Ÿè®¡éªŒè¯çš„å›¾æ•°é‡
            try:
                output_file = Path("exported") / f"{dataset}_export.pkl"
                data = load_data(output_file)
                dataset_graphs = len(data['graphs'])
                total_graphs_validated += dataset_graphs
                print(f"âœ… è¿›åº¦: {success_count}/{len(all_datasets)} æ•°æ®é›†, ç´¯è®¡éªŒè¯ {total_graphs_validated} ä¸ªå›¾")
            except:
                print(f"âœ… è¿›åº¦: {success_count}/{len(all_datasets)} æ•°æ®é›†")
        else:
            print(f"âŒ {dataset} å…¨é¢éªŒè¯å¤±è´¥ï¼Œåœæ­¢æµ‹è¯•")
            break
    
    print("\n" + "=" * 80)
    print(f"ğŸ“Š å…¨é¢éªŒè¯ç»“æœ:")
    print(f"    æˆåŠŸæ•°æ®é›†: {success_count}/{len(all_datasets)}")
    print(f"    éªŒè¯å›¾æ€»æ•°: {total_graphs_validated}")
    
    if success_count == len(all_datasets):
        print("ğŸ‰ æ‰€æœ‰æ•°æ®é›†å…¨é¢éªŒè¯å®Œå…¨é€šè¿‡!")
    else:
        print("ğŸ’¥ éƒ¨åˆ†æ•°æ®é›†éªŒè¯å¤±è´¥!")


if __name__ == "__main__":
    main()