"""
å¯¼å‡ºæ•°æ®ä¸“ç”¨åŠ è½½å™¨
åŸºäºTokenizerGraphé¡¹ç›®å¯¼å‡ºçš„æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
ç¡®ä¿ä¸åŸé¡¹ç›®100%æ•°æ®ä¸€è‡´æ€§
"""

import os
import pickle
import torch
import numpy as np
from torch_geometric.data import Data, InMemoryDataset
from torch_geometric.graphgym.config import cfg
from typing import Dict, List, Any, Optional


class ExportedDataset(InMemoryDataset):
    """
    åŠ è½½TokenizerGraphå¯¼å‡ºçš„æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
    
    æ•°æ®æ ¼å¼ï¼š
    {
        'graphs': List[Dict],      # å›¾æ•°æ®åˆ—è¡¨
        'labels': List[Any],       # æ ‡ç­¾åˆ—è¡¨  
        'splits': Dict[str, np.ndarray],  # æ•°æ®åˆ’åˆ†
        'dataset_info': Dict       # æ•°æ®é›†å…ƒä¿¡æ¯
    }
    """
    
    def __init__(self, 
                 exported_file_path: str,
                 dataset_name: str,
                 transform=None, 
                 pre_transform=None,
                 qm9_target: str = None):
        """
        Args:
            exported_file_path: å¯¼å‡ºçš„pklæ–‡ä»¶è·¯å¾„
            dataset_name: æ•°æ®é›†åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        """
        self.exported_file_path = exported_file_path
        self.dataset_name = dataset_name
        self.qm9_target = qm9_target
        
        if not os.path.exists(exported_file_path):
            raise FileNotFoundError(f"Exported data file not found: {exported_file_path}")
        
        # ä¸´æ—¶rootç›®å½•ï¼ŒInMemoryDatasetéœ€è¦
        temp_root = os.path.dirname(exported_file_path)
        super().__init__(root=temp_root, transform=transform, pre_transform=pre_transform)
        
        # åŠ è½½å¯¼å‡ºæ•°æ®
        self._load_exported_data()
        
    def _load_exported_data(self):
        """åŠ è½½å¯¼å‡ºçš„æ ‡å‡†åŒ–æ•°æ®"""
        print(f"ğŸ”„ Loading exported data: {self.dataset_name}")
        print(f"   File: {self.exported_file_path}")
        
        # åŠ è½½pklæ–‡ä»¶
        with open(self.exported_file_path, 'rb') as f:
            exported_data = pickle.load(f)
        
        # éªŒè¯æ•°æ®æ ¼å¼
        required_keys = ['graphs', 'labels', 'splits']
        for key in required_keys:
            if key not in exported_data:
                raise ValueError(f"Missing key '{key}' in exported data")
        
        graphs_data = exported_data['graphs']
        labels_data = exported_data['labels']
        splits_data = exported_data['splits']
        dataset_info = exported_data.get('dataset_info', {
            'task_type': 'classification',
            'dataset_name': self.dataset_name
        })
        
        print(f"   ğŸ“Š Loaded {len(graphs_data)} graphs")
        print(f"   ğŸ“‹ Task type: {dataset_info.get('task_type', 'unknown')}")
        
        # è½¬æ¢ä¸ºPyGæ ¼å¼
        pyg_data_list = self._convert_to_pyg_format(graphs_data, labels_data)
        
        # ä½¿ç”¨PyGçš„collateæ–¹æ³•å¤„ç†æ•°æ®
        self.data, self.slices = self.collate(pyg_data_list)
        
        # ä¿®å¤å¤šç»´æ ‡ç­¾è¢«å±•å¹³çš„é—®é¢˜
        first_label = pyg_data_list[0].y
        if first_label.dim() > 0 and len(first_label) > 1:
            # å¤šç»´æ ‡ç­¾ï¼šé‡æ–°reshapeå¹¶æ›´æ–°slices
            num_samples = len(pyg_data_list)
            label_dim = len(first_label)
            self.data.y = self.data.y.view(num_samples, label_dim)
            # æ›´æ–°slicesä¿¡æ¯ï¼šæ¯ä¸ªæ ·æœ¬å ä¸€è¡Œ
            self.slices['y'] = torch.arange(0, num_samples + 1)
            
            # QM9å¤šå±æ€§å›å½’ä»»åŠ¡çš„z-scoreæ ‡å‡†åŒ–
            if self.dataset_name == 'qm9' and self.qm9_target == 'all':
                print(f"   ğŸ“Š QM9å¤šå±æ€§å›å½’ï¼šå¯¹{label_dim}ä¸ªå±æ€§è¿›è¡Œz-scoreæ ‡å‡†åŒ–")
                # è®¡ç®—æ¯ä¸ªå±æ€§çš„å‡å€¼å’Œæ ‡å‡†å·®
                self.data.y = (self.data.y - self.data.y.mean(dim=0, keepdim=True)) / (self.data.y.std(dim=0, keepdim=True) + 1e-8)
        
        # è®¾ç½®æ•°æ®åˆ†å‰²
        self._setup_data_splits(splits_data)
        
        # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
        self.dataset_info = dataset_info
        
        print(f"   âœ… Successfully loaded {self.dataset_name}")
    
    def _convert_to_pyg_format(self, graphs_data: List[Dict], labels_data: List[Any]) -> List[Data]:
        """
        å°†å¯¼å‡ºçš„å›¾æ•°æ®è½¬æ¢ä¸ºPyGçš„Dataæ ¼å¼
        
        å¯¼å‡ºæ ¼å¼ï¼š
        {
            'src': np.ndarray,         # æºèŠ‚ç‚¹ID
            'dst': np.ndarray,         # ç›®æ ‡èŠ‚ç‚¹ID  
            'num_nodes': int,          # èŠ‚ç‚¹æ€»æ•°
            'node_feat': np.ndarray,   # èŠ‚ç‚¹ç‰¹å¾ (N, D_node)
            'edge_feat': np.ndarray,   # è¾¹ç‰¹å¾ (E, D_edge)
        }
        """
        pyg_data_list = []
        
        for i, (graph_dict, label) in enumerate(zip(graphs_data, labels_data)):
            # éªŒè¯å›¾æ•°æ®æ ¼å¼
            required_graph_keys = ['src', 'dst', 'num_nodes', 'node_feat', 'edge_feat']
            for key in required_graph_keys:
                if key not in graph_dict:
                    raise ValueError(f"Missing key '{key}' in graph {i}")
            
            # æå–æ•°æ®
            src = graph_dict['src']
            dst = graph_dict['dst'] 
            num_nodes = graph_dict['num_nodes']
            node_feat = graph_dict['node_feat']
            edge_feat = graph_dict['edge_feat']
            
            # è½¬æ¢ä¸ºtorch tensor
            # è¾¹ç´¢å¼•ï¼šå°†src, dstç»„åˆä¸ºedge_index
            edge_index = torch.from_numpy(np.stack([src, dst], axis=0)).long()
            
            # èŠ‚ç‚¹ç‰¹å¾ï¼šç¡®ä¿2Då¹¶è½¬æ¢ä¸ºfloat32
            if node_feat.ndim == 1:
                node_feat = node_feat.reshape(-1, 1)
            x = torch.from_numpy(node_feat).float()  # è½¬æ¢ä¸ºfloat32ä»¥å…¼å®¹Linearå±‚
            
            # è¾¹ç‰¹å¾ï¼šç¡®ä¿2Då¹¶è½¬æ¢ä¸ºfloat32
            if edge_feat.ndim == 1:
                edge_feat = edge_feat.reshape(-1, 1)
            edge_attr = torch.from_numpy(edge_feat).float()  # è½¬æ¢ä¸ºfloat32ä»¥å…¼å®¹Linearå±‚
            
            # æ ‡ç­¾å¤„ç† - æ”¯æŒå¤šç§æ•°æ®ç±»å‹
            if isinstance(label, np.ndarray):
                y = torch.from_numpy(label)
            elif isinstance(label, dict):
                # QM9æ•°æ®é›†çš„ç‰¹æ®Šå¤„ç†
                if self.dataset_name == 'qm9' and self.qm9_target:
                    if self.qm9_target == 'all':
                        # ä½¿ç”¨æ‰€æœ‰å±æ€§è¿›è¡Œå¤šå›å½’ä»»åŠ¡
                        qm9_properties = ['mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'u0', 
                                        'u298', 'h298', 'g298', 'cv', 'u0_atom', 'u298_atom', 'h298_atom', 'g298_atom']
                        y = torch.tensor([label[k] for k in qm9_properties])
                    else:
                        # ä½¿ç”¨æŒ‡å®šå±æ€§è¿›è¡Œå•å›å½’ä»»åŠ¡
                        if self.qm9_target not in label:
                            raise ValueError(f"QM9 target '{self.qm9_target}' not found in label keys: {list(label.keys())}")
                        y = torch.tensor([label[self.qm9_target]])
                else:
                    # å…¶ä»–dictæ ¼å¼æ ‡ç­¾ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    y = torch.tensor([label[k] for k in sorted(label.keys())])
            elif isinstance(label, (int, float, np.integer, np.floating)):
                # æ”¯æŒåŸºæœ¬æ•°æ®ç±»å‹ï¼šint, floatç­‰
                y = torch.tensor([label])
            elif isinstance(label, (list, tuple)):
                # æ”¯æŒåˆ—è¡¨å’Œå…ƒç»„
                y = torch.tensor(label)
            else:
                # å°è¯•ç›´æ¥è½¬æ¢ä¸ºtensor
                try:
                    y = torch.tensor([label])
                except (ValueError, TypeError):
                    raise ValueError(f"Unsupported label type: {type(label)}. Expected np.ndarray, dict, int, float, list, or tuple.")
            
            # ç¡®ä¿æ ‡ç­¾æ˜¯æ­£ç¡®çš„æ•°æ®ç±»å‹
            if y.dtype == torch.int64:
                pass  # åˆ†ç±»ä»»åŠ¡ä¿æŒint64
            else:
                y = y.float()  # å›å½’ä»»åŠ¡è½¬ä¸ºfloat
            
            # åˆ›å»ºPyG Dataå¯¹è±¡
            data = Data(
                x=x,
                edge_index=edge_index,
                edge_attr=edge_attr,
                y=y,
                num_nodes=num_nodes
            )
            
            pyg_data_list.append(data)
        
        return pyg_data_list
    
    def _setup_data_splits(self, splits_data: Dict[str, np.ndarray]):
        """è®¾ç½®æ•°æ®åˆ†å‰²"""
        train_idx = splits_data['train'].tolist()
        val_idx = splits_data['val'].tolist() 
        test_idx = splits_data['test'].tolist()
        
        self.split_idxs = [train_idx, val_idx, test_idx]
        
        # æ·»åŠ GraphGymæœŸæœ›çš„ç´¢å¼•å­—æ®µ
        import torch
        self.data.train_graph_index = torch.tensor(train_idx, dtype=torch.long)
        self.data.val_graph_index = torch.tensor(val_idx, dtype=torch.long)
        self.data.test_graph_index = torch.tensor(test_idx, dtype=torch.long)
        
        print(f"   ğŸ“‹ Data splits:")
        print(f"      Train: {len(train_idx)} samples")
        print(f"      Val:   {len(val_idx)} samples")
        print(f"      Test:  {len(test_idx)} samples")
    
    @property
    def processed_file_names(self):
        return []  # æ•°æ®å·²ç»å¯¼å‡ºå¤„ç†å¥½äº†
    
    def process(self):
        pass  # æ— éœ€é¢å¤–å¤„ç†


# æ•°æ®é›†åç§°åˆ°æ–‡ä»¶åçš„æ˜ å°„
DATASET_FILE_MAPPING = {
    # åˆ†å­æ•°æ®é›†ï¼ˆå›å½’ï¼‰
    'qm9': 'qm9_export.pkl',
    'zinc': 'zinc_export.pkl', 
    'aqsol': 'aqsol_export.pkl',
    'molhiv': 'molhiv_export.pkl',  # äºŒåˆ†ç±»ï¼Œä½†æ”¾åœ¨è¿™é‡Œæ–¹ä¾¿ç®¡ç†
    
    # TUæ•°æ®é›†ï¼ˆåˆ†ç±»ï¼‰
    'colors3': 'colors3_export.pkl',
    'proteins': 'proteins_export.pkl', 
    'dd': 'dd_export.pkl',
    'mutagenicity': 'mutagenicity_export.pkl',
    'coildel': 'coildel_export.pkl',
    'dblp': 'dblp_export.pkl',
    'twitter': 'twitter_export.pkl',
    'synthetic': 'synthetic_export.pkl',
    
    # LRGBæ•°æ®é›†
    'peptides_func': 'peptides_func_export.pkl',
    'peptides_struct': 'peptides_struct_export.pkl',
}


def load_exported_dataset(dataset_name: str, exported_data_dir: str, qm9_target: str = 'homo') -> ExportedDataset:
    """
    åŠ è½½æŒ‡å®šçš„å¯¼å‡ºæ•°æ®é›†
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        exported_data_dir: å¯¼å‡ºæ•°æ®ç›®å½•è·¯å¾„
        
    Returns:
        ExportedDatasetå¯¹è±¡
    """
    if dataset_name not in DATASET_FILE_MAPPING:
        available_datasets = list(DATASET_FILE_MAPPING.keys())
        raise ValueError(f"Unknown dataset '{dataset_name}'. Available: {available_datasets}")
    
    file_name = DATASET_FILE_MAPPING[dataset_name]
    file_path = os.path.join(exported_data_dir, file_name)
    
    return ExportedDataset(
        exported_file_path=file_path,
        dataset_name=dataset_name,
        qm9_target=qm9_target if dataset_name == 'qm9' else None
    )


# ä¸»åŠ è½½å™¨è¦è°ƒç”¨çš„é¢„å¤„ç†å‡½æ•°
def preformat_exported_qm9(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„QM9æ•°æ®"""
    from torch_geometric.graphgym.config import cfg
    
    # æ ¹æ®æ•°æ®é›†åç§°è§£æQM9å±æ€§é…ç½®
    dataset_name = cfg.dataset.name
    if dataset_name == 'QM9-homo':
        qm9_target = 'homo'
    elif dataset_name == 'QM9-gap':
        qm9_target = 'gap'
    elif dataset_name == 'QM9-all':
        qm9_target = 'all'
    elif dataset_name.startswith('QM9-'):
        # æå–å±æ€§åï¼Œå¦‚ QM9-lumo -> lumo
        qm9_target = dataset_name.split('-', 1)[1]
    else:
        # é»˜è®¤ä½¿ç”¨homoå±æ€§
        qm9_target = 'homo'
    
    return load_exported_dataset('qm9', exported_data_dir, qm9_target=qm9_target)

def preformat_exported_zinc(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„ZINCæ•°æ®"""
    return load_exported_dataset('zinc', exported_data_dir)

def preformat_exported_aqsol(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„AQSOLæ•°æ®"""
    return load_exported_dataset('aqsol', exported_data_dir)

def preformat_exported_molhiv(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„MOLHIVæ•°æ®"""
    return load_exported_dataset('molhiv', exported_data_dir)

def preformat_exported_colors3(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„COLORS-3æ•°æ®"""
    return load_exported_dataset('colors3', exported_data_dir)

def preformat_exported_proteins(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„PROTEINSæ•°æ®"""
    return load_exported_dataset('proteins', exported_data_dir)

def preformat_exported_dd(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„DDæ•°æ®"""
    return load_exported_dataset('dd', exported_data_dir)

def preformat_exported_mutagenicity(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„Mutagenicityæ•°æ®"""
    return load_exported_dataset('mutagenicity', exported_data_dir)

def preformat_exported_coildel(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„COIL-DELæ•°æ®"""
    return load_exported_dataset('coildel', exported_data_dir)

def preformat_exported_dblp(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„DBLPæ•°æ®"""
    return load_exported_dataset('dblp', exported_data_dir)

def preformat_exported_twitter(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„TWITTERæ•°æ®"""
    return load_exported_dataset('twitter', exported_data_dir)

def preformat_exported_synthetic(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„SYNTHETICæ•°æ®"""
    return load_exported_dataset('synthetic', exported_data_dir)

def preformat_exported_peptides_func(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„Peptides-funcæ•°æ®"""
    return load_exported_dataset('peptides_func', exported_data_dir)

def preformat_exported_peptides_struct(exported_data_dir):
    """åŠ è½½å¯¼å‡ºçš„Peptides-structæ•°æ®"""
    return load_exported_dataset('peptides_struct', exported_data_dir)
